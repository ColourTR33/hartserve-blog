<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>PART 1: Foundational AI Concepts | Mark Hartley</title><meta name=keywords content="RAG,LLMOps,Security,Token Optimization,Architecture"><meta name=description content="Practical patterns for enterprise AI: RAG, cost control, security, LLMOps, and change management—with templates and pitfalls."><meta name=author content="Mark Hartley"><link rel=canonical href=https://mark.thehartleys.uk/blog/posts/enterprise-ai-1/><link crossorigin=anonymous href=https://mark.thehartleys.uk/blog/assets/css/stylesheet.a090830a421002426baafbd314e38f149d77b4c48a12ee9312700d770b27fb26.css integrity="sha256-oJCDCkIQAkJrqvvTFOOPFJ13tMSKEu6TEnANdwsn+yY=" rel="preload stylesheet" as=style><link rel=icon href=https://mark.thehartleys.uk/blog/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://mark.thehartleys.uk/blog/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://mark.thehartleys.uk/blog/favicon-32x32.png><link rel=apple-touch-icon href=https://mark.thehartleys.uk/blog/apple-touch-icon.png><link rel=mask-icon href=https://mark.thehartleys.uk/blog/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://mark.thehartleys.uk/blog/posts/enterprise-ai-1/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:url" content="https://mark.thehartleys.uk/blog/posts/enterprise-ai-1/"><meta property="og:site_name" content="Mark Hartley"><meta property="og:title" content="PART 1: Foundational AI Concepts"><meta property="og:description" content="Practical patterns for enterprise AI: RAG, cost control, security, LLMOps, and change management—with templates and pitfalls."><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-08-16T00:00:00+00:00"><meta property="article:modified_time" content="2025-08-16T00:00:00+00:00"><meta property="og:image" content="https://mark.thehartleys.uk/posts/enterprise-ai-1/hero.jpg"><meta property="og:see_also" content="https://mark.thehartleys.uk/blog/posts/enterprise-ai-2/"><meta property="og:see_also" content="https://mark.thehartleys.uk/blog/posts/enterprise-ai-3/"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://mark.thehartleys.uk/posts/enterprise-ai-1/hero.jpg"><meta name=twitter:title content="PART 1: Foundational AI Concepts"><meta name=twitter:description content="Practical patterns for enterprise AI: RAG, cost control, security, LLMOps, and change management—with templates and pitfalls."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://mark.thehartleys.uk/blog/posts/"},{"@type":"ListItem","position":2,"name":"PART 1: Foundational AI Concepts","item":"https://mark.thehartleys.uk/blog/posts/enterprise-ai-1/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"PART 1: Foundational AI Concepts","name":"PART 1: Foundational AI Concepts","description":"Practical patterns for enterprise AI: RAG, cost control, security, LLMOps, and change management—with templates and pitfalls.","keywords":["RAG","LLMOps","Security","Token Optimization","Architecture"],"articleBody":"Generative AI is not just another software deployment; it is the integration of a non-deterministic, reasoning workforce into existing business processes. Success hinges on more than technical acumen. It requires a strategic approach to grounding models in enterprise data (Context), managing their unpredictable nature, optimizing for cost (Tokens), and securing the new interfaces they create. This series of posts guides architects in navigating these complexities to deliver tangible business value.\nPart 1: Foundational AI Concepts Types of AI: Choosing the Right Tool for the Job Not all AI is the same. It’s critical to differentiate and apply the correct type to the business problem.\nPredictive/Analytical AI (Traditional AI/ML): What it is: Uses historical data to make predictions about future outcomes (e.g., sales forecasting, customer churn prediction, fraud detection). It answers questions like “What will happen next?” or “Is this an anomaly?”\nAdvantages: Highly deterministic, statistically robust, excellent for classification, regression, and clustering tasks. Anti-Pattern: Using predictive models for generative tasks, like trying to make a classification model write an email.\nGenerative AI (GenAI / LLMs): What it is: Creates new content based on patterns learned from vast datasets (e.g., writing emails, summarizing documents, generating code, creating images). It excels at tasks requiring understanding, reasoning, and creation.\nAdvantages: Flexible, powerful for unstructured data, can handle a wide range of tasks with natural language prompts. Anti-Pattern: Using GenAI for tasks that require 100% factual accuracy and determinism without proper guardrails (like RAG).\nExpecting an LLM to perform high-precision mathematical calculations without tools is a common mistake, however, paired with the appropriate tool or plug-in, such as calculators, search or code execution, LLMs excel.\nCore Components: Query, Context, and Prompt Every interaction with an LLM is a blend of these three elements. Identifying them in a client’s workflow is the first step in solution architecture.\nQuery: The user’s direct question or instruction. It’s the core intent.\nExample: “Summarize the latest status report for Project Titan.”\nContext: The background information the AI needs to answer the Query accurately. This is the most critical element in enterprise settings, as it grounds the AI in the company’s specific reality. Context can be data from a database, document snippets, chat history, or user profile information.\nExample: The actual text of the “Project Titan Status Report.”\nPrompt: The final, packaged instruction sent to the AI model. It skillfully combines the Query, the Context, and any formatting or role-playing instructions.\n*Example: You are a helpful project management assistant. Based on the following document, provide a three-bullet point summary of the status of Project Titan, focusing on risks and next steps. \\n\\n [Context: Paste the full text of the status report here] \\n\\n User Query: “Summarize the latest status report for Project Titan.” *\nIn Architecture Design: Identify data sources that will provide Context. These are your integration points (databases, APIs, document stores).\nDefine the business workflows that will generate the Query.\nThe “Prompt” is the templated logic your application will build before making an API call to the LLM.\nThe Unit of Cost: Understanding and Valuing Tokens Tokens are the currency of LLMs. A token is roughly 4 characters of text though it does vary by model. Every part of the prompt (Query, Context, instructions) and the AI’s response consumes tokens, which translates directly to cost and impacts performance. Mismanagement is expensive.\nThe Nature of AI: Managing Non-Determinism LLMs are probabilistic, not deterministic. Asking the same question twice may yield slightly different answers. This is a feature (creativity) but also a challenge for enterprise applications that expect consistency.\nHow to Bake This into Solutions: Control Temperature: For tasks requiring more factual and consistent outputs (like data extraction), set the model’s temperature parameter to a low value (e.g., 0.1 or 0) - note that the output still remains probabilistic. For creative tasks, a higher temperature is acceptable.\nImplement a Validation Layer: For critical workflows, have a second, independent process (either another AI call or a rule-based system) validate the output of the first. Example: If extracting invoice numbers, use a regex check to ensure the output is in the correct format.\nStructure the Output: Instruct the model to respond in a structured format like JSON. This makes the output machine-readable and easier to validate.\nUI/UX Design: Never present AI output as infallible fact. The UI should include mechanisms for users to flag incorrect answers, regenerate responses, and understand that the content is AI-generated.\n","wordCount":"733","inLanguage":"en","image":"https://mark.thehartleys.uk/posts/enterprise-ai-1/hero.jpg","datePublished":"2025-08-16T00:00:00Z","dateModified":"2025-08-16T00:00:00Z","author":{"@type":"Person","name":"Mark Hartley"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://mark.thehartleys.uk/blog/posts/enterprise-ai-1/"},"publisher":{"@type":"Organization","name":"Mark Hartley","logo":{"@type":"ImageObject","url":"https://mark.thehartleys.uk/blog/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://mark.thehartleys.uk/blog/ accesskey=h title="Mark Hartley (Alt + H)">Mark Hartley</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://mark.thehartleys.uk/blog/posts/ title="Other Posts"><span>Other Posts</span></a></li><li><a href=https://mark.thehartleys.uk/blog/series/enterprise-ai-design-patterns/ title=Series><span>Series</span></a></li><li><a href=https://mark.thehartleys.uk/blog/cv/mark-hartley-cv.pdf title="Curriculum Vitae"><span>Curriculum Vitae</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://mark.thehartleys.uk/blog/>Home</a>&nbsp;»&nbsp;<a href=https://mark.thehartleys.uk/blog/posts/>Posts</a></div><h1 class=post-title>PART 1: Foundational AI Concepts</h1><div class=post-description>Practical patterns for enterprise AI: RAG, cost control, security, LLMOps, and change management—with templates and pitfalls.</div><div class=post-meta><span title='2025-08-16 00:00:00 +0000 UTC'>August 16, 2025</span>&nbsp;·&nbsp;<span>4 min</span>&nbsp;·&nbsp;<span>Mark Hartley</span></div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#part-1-foundational-ai-concepts aria-label="Part 1: Foundational AI Concepts">Part 1: Foundational AI Concepts</a><ul><li><a href=#types-of-ai-choosing-the-right-tool-for-the-job aria-label="Types of AI: Choosing the Right Tool for the Job">Types of AI: Choosing the Right Tool for the Job</a><ul><li><a href=#predictiveanalytical-ai-traditional-aiml aria-label="Predictive/Analytical AI (Traditional AI/ML):">Predictive/Analytical AI (Traditional AI/ML):</a></li><li><a href=#generative-ai-genai--llms aria-label="Generative AI (GenAI / LLMs):">Generative AI (GenAI / LLMs):</a></li></ul></li><li><a href=#core-components-query-context-and-prompt aria-label="Core Components: Query, Context, and Prompt">Core Components: Query, Context, and Prompt</a><ul><li><a href=#in-architecture-design aria-label="In Architecture Design:">In Architecture Design:</a></li></ul></li><li><a href=#the-unit-of-cost-understanding-and-valuing-tokens aria-label="The Unit of Cost: Understanding and Valuing Tokens">The Unit of Cost: Understanding and Valuing Tokens</a></li><li><a href=#the-nature-of-ai-managing-non-determinism aria-label="The Nature of AI: Managing Non-Determinism">The Nature of AI: Managing Non-Determinism</a><ul><li><a href=#how-to-bake-this-into-solutions aria-label="How to Bake This into Solutions:">How to Bake This into Solutions:</a></li></ul></li></ul></li></ul></div></details></div><div class=post-content><p>Generative AI is not just another software deployment; it is the integration of a non-deterministic, reasoning workforce into existing business processes. Success hinges on more than technical acumen. It requires a strategic approach to grounding models in enterprise data (Context), managing their unpredictable nature, optimizing for cost (Tokens), and securing the new interfaces they create. This series of posts guides architects in navigating these complexities to deliver tangible business value.</p><h2 id=part-1-foundational-ai-concepts>Part 1: Foundational AI Concepts</h2><h3 id=types-of-ai-choosing-the-right-tool-for-the-job>Types of AI: Choosing the Right Tool for the Job</h3><p>Not all AI is the same. It&rsquo;s critical to differentiate and apply the correct type to the business problem.</p><h4 id=predictiveanalytical-ai-traditional-aiml>Predictive/Analytical AI (Traditional AI/ML):</h4><p><strong>What it is:</strong> Uses historical data to make predictions about future outcomes (e.g., sales forecasting, customer churn prediction, fraud detection). It answers questions like &ldquo;What will happen next?&rdquo; or &ldquo;Is this an anomaly?&rdquo;</p><p><strong>Advantages:</strong> Highly deterministic, statistically robust, excellent for classification, regression, and clustering tasks.
<strong>Anti-Pattern:</strong> Using predictive models for generative tasks, like trying to make a classification model write an email.</p><h4 id=generative-ai-genai--llms>Generative AI (GenAI / LLMs):</h4><p><strong>What it is:</strong> Creates new content based on patterns learned from vast datasets (e.g., writing emails, summarizing documents, generating code, creating images). It excels at tasks requiring understanding, reasoning, and creation.</p><p><strong>Advantages:</strong> Flexible, powerful for unstructured data, can handle a wide range of tasks with natural language prompts.
<strong>Anti-Pattern:</strong> Using GenAI for tasks that require 100% factual accuracy and determinism without proper guardrails (like RAG).</p><p>Expecting an LLM to perform high-precision mathematical calculations without tools is a common mistake, however, paired with the appropriate tool or plug-in, such as calculators, search or code execution, LLMs excel.</p><h3 id=core-components-query-context-and-prompt>Core Components: Query, Context, and Prompt</h3><p>Every interaction with an LLM is a blend of these three elements. Identifying them in a client&rsquo;s workflow is the first step in solution architecture.</p><p><strong>Query:</strong> The user&rsquo;s direct question or instruction. It&rsquo;s the core intent.</p><p><em>Example: &ldquo;Summarize the latest status report for Project Titan.&rdquo;</em></p><p><strong>Context:</strong> The background information the AI needs to answer the Query accurately. This is the most critical element in enterprise settings, as it grounds the AI in the company&rsquo;s specific reality. Context can be data from a database, document snippets, chat history, or user profile information.</p><p><em>Example: The actual text of the &ldquo;Project Titan Status Report.&rdquo;</em></p><p><strong>Prompt:</strong> The final, packaged instruction sent to the AI model. It skillfully combines the Query, the Context, and any formatting or role-playing instructions.</p><p>*Example: You are a helpful project management assistant. Based on the following document, provide a three-bullet point summary of the status of Project Titan, focusing on risks and next steps. \n\n [Context: Paste the full text of the status report here] \n\n User Query: &ldquo;Summarize the latest status report for Project Titan.&rdquo;
*</p><h4 id=in-architecture-design>In Architecture Design:</h4><ul><li><p>Identify data sources that will provide <em>Context</em>. These are your integration points (databases, APIs, document stores).</p></li><li><p>Define the business workflows that will generate the <em>Query</em>.</p></li><li><p>The &ldquo;<em>Prompt</em>&rdquo; is the templated logic your application will build before making an API call to the LLM.</p></li></ul><h3 id=the-unit-of-cost-understanding-and-valuing-tokens>The Unit of Cost: Understanding and Valuing Tokens</h3><p>Tokens are the currency of LLMs. A token is roughly <em>4 characters of text</em> though it does vary by model. Every part of the prompt (Query, Context, instructions) and the AI&rsquo;s response consumes tokens, which translates directly to cost and impacts performance. <strong>Mismanagement is expensive</strong>.</p><h3 id=the-nature-of-ai-managing-non-determinism>The Nature of AI: Managing Non-Determinism</h3><p>LLMs are probabilistic, not deterministic. Asking the same question twice may yield slightly different answers. This is a feature (creativity) but also a challenge for enterprise applications that expect consistency.</p><h4 id=how-to-bake-this-into-solutions>How to Bake This into Solutions:</h4><p><strong>Control Temperature:</strong> For tasks requiring more factual and consistent outputs (like data extraction), set the model&rsquo;s temperature parameter to a low value (e.g., 0.1 or 0) - <em>note that the output still remains probabilistic</em>. For creative tasks, a higher temperature is acceptable.</p><p><strong>Implement a Validation Layer:</strong> For critical workflows, have a second, independent process (either another AI call or a rule-based system) validate the output of the first. <em>Example: If extracting invoice numbers, use a regex check to ensure the output is in the correct format.</em></p><p><strong>Structure the Output:</strong> Instruct the model to respond in a structured format like JSON. This makes the output machine-readable and easier to validate.</p><p><strong>UI/UX Design:</strong> <em>Never present AI output as infallible fact.</em> The UI should include mechanisms for users to flag incorrect answers, regenerate responses, and understand that the content is AI-generated.</p></div><footer class=post-footer><ul class=post-tags></ul><nav class=paginav><a class=next href=https://mark.thehartleys.uk/blog/posts/enterprise-ai-2/><span class=title>Next »</span><br><span>PPart 2: Architectural Patterns & Implementation</span></a></nav></footer></article></main><footer class=footer><span>&copy; 2025 <a href=https://mark.thehartleys.uk/blog/>Mark Hartley</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>